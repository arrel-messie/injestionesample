#!/bin/bash
set -eu

source "$(dirname "${BASH_SOURCE[0]}")/common.sh"

[ $# -lt 1 ] && { echo "Usage: $0 <environment> [schema_version] [output_file]" >&2; exit 1; }

ENV=$1
SCHEMA_VERSION=${2:-"${ENV}-latest"}
OUTPUT_FILE=${3:-"$MODULE_ROOT/druid-specs/generated/supervisor-spec-${ENV}.json"}

validate_environment "$ENV"
check_command envsubst
check_command jq

load_config "$ENV"
validate_vars "$MODULE_ROOT/config/${ENV}.env" \
    KAFKA_BOOTSTRAP_SERVERS KAFKA_TOPIC DATASOURCE_NAME

# Export config vars
export SCHEMA_VERSION
export ENVIRONMENT="$ENV"
export KAFKA_BOOTSTRAP_SERVERS
export KAFKA_SASL_JAAS_CONFIG="${KAFKA_SASL_JAAS_CONFIG:-}"
export KAFKA_TOPIC
export KAFKA_SECURITY_PROTOCOL
export KAFKA_SASL_MECHANISM
export KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM="${KAFKA_SSL_ENDPOINT_IDENTIFICATION_ALGORITHM:-}"
export PROTO_DESCRIPTOR_FILE
export PROTO_MESSAGE_TYPE
export DATASOURCE_NAME
export TIMESTAMP_COLUMN
export TIMESTAMP_FORMAT
export DRUID_OVERLORD_URL="${DRUID_OVERLORD_URL:-}"
export SECONDARY_PARTITION_DIMENSIONS="${SECONDARY_PARTITION_DIMENSIONS:-[]}"
export S3_BUCKET="${S3_BUCKET:-my-company-druid-schemas}"
export TX_TYPE_VALIDATION_FILTER="${TX_TYPE_VALIDATION_FILTER:-null}"

# Load JSON configs
for json_file in dimensions metrics transforms index-spec; do
    file="$MODULE_ROOT/config/${json_file}.json"
    check_file "$file"
    json_content=$(jq -c . "$file" 2>&1)
    if [ $? -ne 0 ] || [ -z "$json_content" ]; then
        echo "ERROR: Invalid JSON: $file" >&2
        exit 1
    fi
    case "$json_file" in
        dimensions) export DIMENSIONS_JSON="$json_content" ;;
        metrics) export METRICS_JSON="$json_content" ;;
        transforms) export TRANSFORMS_JSON="$json_content" ;;
        index-spec) export INDEX_SPEC_JSON="$json_content" ;;
    esac
done

# Set defaults
export KAFKA_FETCH_MIN_BYTES="${KAFKA_FETCH_MIN_BYTES:-1048576}"
export KAFKA_FETCH_MAX_WAIT_MS="${KAFKA_FETCH_MAX_WAIT_MS:-500}"
export KAFKA_MAX_POLL_RECORDS="${KAFKA_MAX_POLL_RECORDS:-500}"
export KAFKA_SESSION_TIMEOUT_MS="${KAFKA_SESSION_TIMEOUT_MS:-30000}"
export KAFKA_HEARTBEAT_INTERVAL_MS="${KAFKA_HEARTBEAT_INTERVAL_MS:-3000}"
export KAFKA_MAX_POLL_INTERVAL_MS="${KAFKA_MAX_POLL_INTERVAL_MS:-300000}"
export KAFKA_AUTO_OFFSET_RESET="${KAFKA_AUTO_OFFSET_RESET:-latest}"
export USE_EARLIEST_OFFSET="${USE_EARLIEST_OFFSET:-false}"
export USE_TRANSACTION="${USE_TRANSACTION:-true}"
export TASK_COUNT="${TASK_COUNT:-10}"
export REPLICAS="${REPLICAS:-2}"
export TASK_DURATION="${TASK_DURATION:-PT1H}"
export START_DELAY="${START_DELAY:-PT5S}"
export PERIOD="${PERIOD:-PT30S}"
export COMPLETION_TIMEOUT="${COMPLETION_TIMEOUT:-PT1H}"
export LATE_MESSAGE_REJECTION_PERIOD="${LATE_MESSAGE_REJECTION_PERIOD:-PT1H}"
export POLL_TIMEOUT="${POLL_TIMEOUT:-100}"
export MINIMUM_MESSAGE_TIME="${MINIMUM_MESSAGE_TIME:-1970-01-01T00:00:00.000Z}"
export MAX_ROWS_IN_MEMORY="${MAX_ROWS_IN_MEMORY:-500000}"
export MAX_BYTES_IN_MEMORY="${MAX_BYTES_IN_MEMORY:-536870912}"
export MAX_ROWS_PER_SEGMENT="${MAX_ROWS_PER_SEGMENT:-5000000}"
export INTERMEDIATE_PERSIST_PERIOD="${INTERMEDIATE_PERSIST_PERIOD:-PT10M}"
export MAX_PENDING_PERSISTS="${MAX_PENDING_PERSISTS:-2}"
export REPORT_PARSE_EXCEPTIONS="${REPORT_PARSE_EXCEPTIONS:-true}"
export HANDOFF_CONDITION_TIMEOUT="${HANDOFF_CONDITION_TIMEOUT:-900000}"
export RESET_OFFSET_AUTOMATICALLY="${RESET_OFFSET_AUTOMATICALLY:-false}"
export CHAT_RETRIES="${CHAT_RETRIES:-8}"
export HTTP_TIMEOUT="${HTTP_TIMEOUT:-PT10S}"
export SHUTDOWN_TIMEOUT="${SHUTDOWN_TIMEOUT:-PT80S}"
export OFFSET_FETCH_PERIOD="${OFFSET_FETCH_PERIOD:-PT30S}"
export INTERMEDIATE_HANDOFF_PERIOD="${INTERMEDIATE_HANDOFF_PERIOD:-P2147483647D}"
export LOG_PARSE_EXCEPTIONS="${LOG_PARSE_EXCEPTIONS:-true}"
export MAX_PARSE_EXCEPTIONS="${MAX_PARSE_EXCEPTIONS:-10000}"
export MAX_SAVED_PARSE_EXCEPTIONS="${MAX_SAVED_PARSE_EXCEPTIONS:-100}"
export SKIP_SEQUENCE_NUMBER_AVAILABILITY_CHECK="${SKIP_SEQUENCE_NUMBER_AVAILABILITY_CHECK:-false}"
export PARTITIONS_SPEC_TYPE="${PARTITIONS_SPEC_TYPE:-dynamic}"
export TARGET_ROWS_PER_SEGMENT="${TARGET_ROWS_PER_SEGMENT:-5000000}"
export MAX_SPLIT_SIZE="${MAX_SPLIT_SIZE:-1073741824}"
export MAX_INPUT_SEGMENT_BYTES_PER_TASK="${MAX_INPUT_SEGMENT_BYTES_PER_TASK:-10737418240}"
export SEGMENT_GRANULARITY="${SEGMENT_GRANULARITY:-DAY}"
export QUERY_GRANULARITY="${QUERY_GRANULARITY:-NONE}"
export ROLLUP="${ROLLUP:-false}"

# Handle descriptor path
if [ -z "${PROTO_DESCRIPTOR_PATH:-}" ]; then
    export PROTO_DESCRIPTOR_PATH="s3://${S3_BUCKET}/schemas/${SCHEMA_VERSION}/${PROTO_DESCRIPTOR_FILE:-settlement_transaction.desc}"
fi
[[ "$PROTO_DESCRIPTOR_PATH" != file://* && "$PROTO_DESCRIPTOR_PATH" != s3://* ]] && \
    export PROTO_DESCRIPTOR_PATH="file://${PROTO_DESCRIPTOR_PATH}"
export PROTO_DESCRIPTOR_PATH_CLEAN="$PROTO_DESCRIPTOR_PATH"
export PROTO_DECODER_TYPE="file"

# Generate spec
TEMPLATE="$MODULE_ROOT/druid-specs/templates/kafka-supervisor.json"
check_file "$TEMPLATE"
mkdir -p "$(dirname "$OUTPUT_FILE")"
rm -f "$OUTPUT_FILE"

envsubst < "$TEMPLATE" > "$OUTPUT_FILE"
jq empty "$OUTPUT_FILE" || { echo "ERROR: Invalid JSON generated" >&2; exit 1; }

echo "$OUTPUT_FILE"

