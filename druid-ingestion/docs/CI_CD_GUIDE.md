# Guide CI/CD Professionnel

## ğŸ¯ Objectif

Solution professionnelle pour dÃ©ployer automatiquement :
1. **GÃ©nÃ©ration de la spec** d'ingestion Druid
2. **DÃ©ploiement de la spec** sur un serveur Druid distant
3. **Upload du fichier .desc** sur un stockage distant (S3)
4. **Tout via GitLab CI/CD**

## ğŸ“‹ Architecture

```
GitLab CI Pipeline
â”œâ”€â”€ Stage: build
â”‚   â””â”€â”€ Job: build
â”‚       â”œâ”€â”€ Compile protobuf (.desc)
â”‚       â””â”€â”€ Generate specs (JSON)
â”‚
â””â”€â”€ Stage: deploy
    â”œâ”€â”€ Job: deploy:dev (manuel)
    â”œâ”€â”€ Job: deploy:staging (manuel)
    â””â”€â”€ Job: deploy:prod (manuel)
        â”œâ”€â”€ Upload .desc â†’ S3
        â””â”€â”€ Deploy spec â†’ Druid
```

## ğŸš€ Utilisation

### 1. Configuration GitLab

Dans **Settings â†’ CI/CD â†’ Variables**, ajouter :

**Variables communes :**
- `PROTO_MESSAGE_TYPE` = `com.company.PaymentTransactionEvent`
- `AWS_ACCESS_KEY_ID` = `AKIA...` (masquÃ©e)
- `AWS_SECRET_ACCESS_KEY` = `...` (masquÃ©e)

**Variables DEV :**
- `KAFKA_BOOTSTRAP_SERVERS_DEV` = `kafka-dev:9092`
- `KAFKA_TOPIC_DEV` = `settlement-transactions-dev`
- `DRUID_OVERLORD_URL_DEV` = `http://druid-dev:8090`
- `DATASOURCE_NAME_DEV` = `idm_settlement_snapshot_dev`
- `S3_BUCKET_DEV` = `druid-schemas-dev`
- `PROTO_DESCRIPTOR_PATH_DEV` = `s3://druid-schemas-dev/schemas/settlement_transaction.desc`

**Variables STAGING/PROD :** (mÃªme structure avec _STAGING/_PROD)

### 2. Workflow

```bash
# 1. Push sur feature branch
git push origin feature/my-feature

# 2. Merge request â†’ build automatique
#    - Compile .desc
#    - GÃ©nÃ¨re specs

# 3. Merge dans develop â†’ build automatique

# 4. DÃ©ploiement manuel DEV
#    - GitLab CI/CD â†’ Pipelines â†’ Play â–¶ï¸ deploy:dev
#    - Upload .desc â†’ S3
#    - Deploy spec â†’ Druid

# 5. Merge dans main â†’ build automatique

# 6. DÃ©ploiement manuel PROD
#    - GitLab CI/CD â†’ Pipelines â†’ Play â–¶ï¸ deploy:prod
```

## ğŸ”§ Commandes Locales (pour test)

```bash
# Compiler le protobuf
./druid-ingestion.sh compile-proto

# GÃ©nÃ©rer la spec
./druid-ingestion.sh build -e dev

# DÃ©ployer (nÃ©cessite config)
./druid-ingestion.sh deploy -e dev

# VÃ©rifier le statut
./druid-ingestion.sh status -e dev
```

## ğŸ“¦ Fichiers GÃ©nÃ©rÃ©s

### Build Stage
- `schemas/compiled/settlement_transaction.desc` â†’ Artifact
- `druid-specs/generated/supervisor-spec-*-dev.json` â†’ Artifact

### Deploy Stage
- Upload `.desc` â†’ `s3://bucket/schemas/settlement_transaction.desc`
- Deploy `.json` â†’ `http://druid-overlord/druid/indexer/v1/supervisor`

## âœ… Avantages de cette approche

1. **Automatisation** : Build automatique sur chaque push
2. **SÃ©curitÃ©** : DÃ©ploiements manuels pour Ã©viter les erreurs
3. **TraÃ§abilitÃ©** : Tous les dÃ©ploiements tracÃ©s dans GitLab
4. **ReproductibilitÃ©** : MÃªme processus pour tous les environnements
5. **SimplicitÃ©** : Un seul script, une seule pipeline

## ğŸ”’ SÃ©curitÃ©

- Variables masquÃ©es dans GitLab
- DÃ©ploiements manuels uniquement
- Credentials AWS via variables GitLab
- Pas de secrets dans le code

## ğŸ› Troubleshooting

### Build Ã©choue
- VÃ©rifier que `protoc` est installÃ© dans l'image
- VÃ©rifier les chemins des fichiers proto

### Deploy Ã©choue
- VÃ©rifier les variables d'environnement
- VÃ©rifier la connectivitÃ© au Druid Overlord
- VÃ©rifier les credentials AWS pour S3

### Spec invalide
- VÃ©rifier `config/schema.yml`
- VÃ©rifier `config/defaults.yml`
- Tester localement avec `./druid-ingestion.sh build -e dev`
