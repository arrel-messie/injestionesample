# Infra file to simulate data ingestion  on druid to kafka
name: infra
volumes:
  middle_var: {}
  historical_var: {}
  broker_var: {}
  coordinator_var: {}
  router_var: {}
  druid_shared: {}
  kafka-data: {}
  gitlab_config: {}
  gitlab_logs: {}
  gitlab_data: {}

networks:
  druid_network:
    name: druid_network
  resource_network:
    external: true
    name: resource-network

services:
  zookeeper:
    container_name: zookeeper
    image: zookeeper:3.5.10
    ports:
      - "2181:2181"
    environment:
      - ZOO_MY_ID=${ZOO_MY_ID:-1}
    networks:
      - druid_network
    healthcheck:
      test: ["CMD-SHELL", "zkServer.sh status || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped

  coordinator:
    image: apache/druid:30.0.0
    container_name: coordinator
    volumes:
      - druid_shared:/opt/shared
      - coordinator_var:/opt/druid/var
      - ../druid-ingestion/schemas/compiled:/opt/shared/schemas:ro
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "8081:8081"
    command:
      - coordinator
    environment:
      - druid_zk_service_host=zookeeper
      - DRUID_EXTENSIONS_LOADLIST=["druid-histogram", "druid-datasketches", "druid-lookups-cached-global", "druid-multi-stage-query", "druid-kafka-indexing-service", "druid-protobuf-extensions"]
    env_file:
      - .env
    networks:
      - druid_network
      - resource_network
    restart: unless-stopped

  broker:
    image: apache/druid:30.0.0
    container_name: broker
    volumes:
      - broker_var:/opt/druid/var
    depends_on:
      zookeeper:
        condition: service_healthy
      coordinator:
        condition: service_started
    ports:
      - "8082:8082"
    command:
      - broker
    environment:
      - druid_zk_service_host=zookeeper
      - DRUID_EXTENSIONS_LOADLIST=["druid-histogram", "druid-datasketches", "druid-lookups-cached-global", "druid-multi-stage-query", "druid-kafka-indexing-service", "druid-protobuf-extensions"]
    env_file:
      - .env
    networks:
      - druid_network
      - resource_network
    restart: unless-stopped

  historical:
    image: apache/druid:30.0.0
    container_name: historical
    volumes:
      - druid_shared:/opt/shared
      - historical_var:/opt/druid/var
      - ../druid-ingestion/schemas/compiled:/opt/shared/schemas:ro
    depends_on:
      zookeeper:
        condition: service_healthy
      coordinator:
        condition: service_started
    ports:
      - "8083:8083"
    command:
      - historical
    environment:
      - druid_zk_service_host=zookeeper
      - DRUID_EXTENSIONS_LOADLIST=["druid-histogram", "druid-datasketches", "druid-lookups-cached-global", "druid-multi-stage-query", "druid-kafka-indexing-service", "druid-protobuf-extensions"]
    env_file:
      - .env
    networks:
      - druid_network
      - resource_network
    restart: unless-stopped

  middlemanager:
    image: apache/druid:30.0.0
    container_name: middlemanager
    volumes:
      - druid_shared:/opt/shared
      - middle_var:/opt/druid/var
      - ../druid-ingestion/schemas/compiled:/opt/shared/schemas:ro
    depends_on:
      zookeeper:
        condition: service_healthy
      coordinator:
        condition: service_started
    ports:
      - "8091:8091"
      - "8100-8105:8100-8105"
    command:
      - middleManager
    environment:
      - druid_zk_service_host=zookeeper
      - DRUID_EXTENSIONS_LOADLIST=["druid-histogram", "druid-datasketches", "druid-lookups-cached-global", "druid-multi-stage-query", "druid-kafka-indexing-service", "druid-protobuf-extensions"]
    env_file:
      - .env
    networks:
      - druid_network
      - resource_network
    restart: unless-stopped

  router:
    image: apache/druid:30.0.0
    container_name: router
    volumes:
      - router_var:/opt/druid/var
    depends_on:
      zookeeper:
        condition: service_healthy
      coordinator:
        condition: service_started
    ports:
      - "8888:8888"
    command:
      - router
    environment:
      - druid_zk_service_host=zookeeper
    env_file:
      - .env
    networks:
      - druid_network
      - resource_network
    restart: unless-stopped

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    hostname: kafka
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:29093
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,CONTROLLER://0.0.0.0:29093,EXTERNAL://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LOG_DIRS: /var/lib/kafka/data
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk
    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - druid_network
      - resource_network
    healthcheck:
      test: [ "CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5

#  schema-registry:
#    image: confluentinc/cp-schema-registry:7.5.0
#    hostname: schema-registry
#    container_name: schema-registry
#    depends_on:
#      kafka:
#        condition: service_healthy
#      zookeeper:
#        condition: service_healthy
#    ports:
#      - "8085:8081"
#    environment:
#      SCHEMA_REGISTRY_HOST_NAME: schema-registry
#      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: kafka:29092
#      SCHEMA_REGISTRY_KAFKASTORE_TOPIC: _schemas
#      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
#      SCHEMA_REGISTRY_KAFKASTORE_TOPIC_REPLICATION_FACTOR: 1
#    networks:
#      - druid_network
#      - resource_network
#    healthcheck:
#      test: [ "CMD-SHELL", "curl -f http://localhost:8081/subjects || exit 1" ]
#      interval: 10s
#      timeout: 5s
#      retries: 5
#    restart: unless-stopped

  akhq:
    image: tchiotludo/akhq:latest
    container_name: akhq
    hostname: akhq
    depends_on:
      kafka:
        condition: service_healthy
#      schema-registry:
#        condition: service_healthy
    ports:
      - "8084:8080"
    environment:
      AKHQ_CONFIGURATION: |
        akhq:
          connections:
            docker-kafka:
              properties:
                bootstrap.servers: "kafka:29092"
          server:
            access-log:
              enabled: false
          micronaut:
            security:
              token:
                jwt:
                  signatures:
                    secret:
                      generator:
                        secret: "akhq-secret-key-change-in-production-min-256-bits"
          ui:
            topic:
              default-view: ALL
              skip-consumer-groups: false
              skip-last-record: false
          # Security disabled for development - allows access without authentication
          # security:
          #   default-group: admin
          #   groups:
          #     admin:
          #       roles:
          #         - topic/read
          #         - topic/create
          #         - topic/insert
          #         - topic/delete
          #         - topic/config/update
          #         - topic/data/read
          #         - topic/data/insert
          #         - topic/data/delete
          #         - group/read
          #         - group/delete
          #         - group/offsets/update
          #   basic-auth:
          #     - user: admin
          #       password: admin
          #       groups:
          #         - admin
    networks:
      - resource_network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:8080/api/cluster || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5


  gitlab:
    image: gitlab/gitlab-ce:latest
    container_name: resources_gitlab
    hostname: gitlab.localhost
    ports:
      - "${GITLAB_HTTP_PORT:-8080}:80"
      - "${GITLAB_HTTPS_PORT:-8443}:443"
      - "${GITLAB_SSH_PORT:-2222}:22"
    environment:
      GITLAB_OMNIBUS_CONFIG: |
        external_url 'http://gitlab.localhost'
        gitlab_rails['gitlab_shell_ssh_port'] = 2222
        gitlab_rails['initial_root_password'] = '${GITLAB_ROOT_PASSWORD:-MyVeryStr0ng!Pass2024}'
    volumes:
      - gitlab_config:/etc/gitlab
      - gitlab_logs:/var/log/gitlab
      - gitlab_data:/var/opt/gitlab
    networks:
      - druid_network
      - resource_network
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost/-/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s

